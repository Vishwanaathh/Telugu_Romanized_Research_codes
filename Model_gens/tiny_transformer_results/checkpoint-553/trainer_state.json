{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 553,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018083182640144666,
      "grad_norm": 4.207064628601074,
      "learning_rate": 1.98372513562387e-05,
      "loss": 0.7038320541381836,
      "step": 10
    },
    {
      "epoch": 0.03616636528028933,
      "grad_norm": 4.690009593963623,
      "learning_rate": 1.9656419529837254e-05,
      "loss": 0.692609453201294,
      "step": 20
    },
    {
      "epoch": 0.054249547920433995,
      "grad_norm": 3.4036903381347656,
      "learning_rate": 1.9475587703435806e-05,
      "loss": 0.6895005226135253,
      "step": 30
    },
    {
      "epoch": 0.07233273056057866,
      "grad_norm": 6.690968036651611,
      "learning_rate": 1.929475587703436e-05,
      "loss": 0.6738694190979004,
      "step": 40
    },
    {
      "epoch": 0.09041591320072333,
      "grad_norm": 6.010591983795166,
      "learning_rate": 1.911392405063291e-05,
      "loss": 0.6701160907745362,
      "step": 50
    },
    {
      "epoch": 0.10849909584086799,
      "grad_norm": 2.447598695755005,
      "learning_rate": 1.8933092224231466e-05,
      "loss": 0.6921838760375977,
      "step": 60
    },
    {
      "epoch": 0.12658227848101267,
      "grad_norm": 3.8624649047851562,
      "learning_rate": 1.875226039783002e-05,
      "loss": 0.6950963973999024,
      "step": 70
    },
    {
      "epoch": 0.14466546112115733,
      "grad_norm": 4.832038879394531,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.7153438091278076,
      "step": 80
    },
    {
      "epoch": 0.162748643761302,
      "grad_norm": 2.485089063644409,
      "learning_rate": 1.8390596745027126e-05,
      "loss": 0.6730682849884033,
      "step": 90
    },
    {
      "epoch": 0.18083182640144665,
      "grad_norm": 2.530341386795044,
      "learning_rate": 1.8209764918625678e-05,
      "loss": 0.7056440830230712,
      "step": 100
    },
    {
      "epoch": 0.19891500904159132,
      "grad_norm": 6.224339485168457,
      "learning_rate": 1.8028933092224232e-05,
      "loss": 0.6659965991973877,
      "step": 110
    },
    {
      "epoch": 0.21699819168173598,
      "grad_norm": 3.147644281387329,
      "learning_rate": 1.7848101265822787e-05,
      "loss": 0.657301378250122,
      "step": 120
    },
    {
      "epoch": 0.23508137432188064,
      "grad_norm": 2.7148091793060303,
      "learning_rate": 1.7667269439421338e-05,
      "loss": 0.6943887233734131,
      "step": 130
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 5.2769012451171875,
      "learning_rate": 1.7486437613019893e-05,
      "loss": 0.6870117664337159,
      "step": 140
    },
    {
      "epoch": 0.27124773960216997,
      "grad_norm": 2.7742466926574707,
      "learning_rate": 1.7305605786618447e-05,
      "loss": 0.6774771690368653,
      "step": 150
    },
    {
      "epoch": 0.28933092224231466,
      "grad_norm": 2.953896999359131,
      "learning_rate": 1.7124773960217002e-05,
      "loss": 0.6515581130981445,
      "step": 160
    },
    {
      "epoch": 0.3074141048824593,
      "grad_norm": 6.272484302520752,
      "learning_rate": 1.6943942133815553e-05,
      "loss": 0.6871731758117676,
      "step": 170
    },
    {
      "epoch": 0.325497287522604,
      "grad_norm": 3.2082748413085938,
      "learning_rate": 1.6763110307414104e-05,
      "loss": 0.6931763648986816,
      "step": 180
    },
    {
      "epoch": 0.3435804701627486,
      "grad_norm": 3.4691274166107178,
      "learning_rate": 1.658227848101266e-05,
      "loss": 0.6553941249847413,
      "step": 190
    },
    {
      "epoch": 0.3616636528028933,
      "grad_norm": 5.363173484802246,
      "learning_rate": 1.6401446654611213e-05,
      "loss": 0.7039049148559571,
      "step": 200
    },
    {
      "epoch": 0.379746835443038,
      "grad_norm": 2.5617072582244873,
      "learning_rate": 1.6220614828209768e-05,
      "loss": 0.6397264957427978,
      "step": 210
    },
    {
      "epoch": 0.39783001808318263,
      "grad_norm": 2.968327283859253,
      "learning_rate": 1.603978300180832e-05,
      "loss": 0.6567267894744873,
      "step": 220
    },
    {
      "epoch": 0.4159132007233273,
      "grad_norm": 3.3370397090911865,
      "learning_rate": 1.5858951175406874e-05,
      "loss": 0.6555732727050781,
      "step": 230
    },
    {
      "epoch": 0.43399638336347196,
      "grad_norm": 2.7748851776123047,
      "learning_rate": 1.5678119349005428e-05,
      "loss": 0.6083516597747802,
      "step": 240
    },
    {
      "epoch": 0.45207956600361665,
      "grad_norm": 2.9879355430603027,
      "learning_rate": 1.549728752260398e-05,
      "loss": 0.6426461696624756,
      "step": 250
    },
    {
      "epoch": 0.4701627486437613,
      "grad_norm": 2.377814769744873,
      "learning_rate": 1.531645569620253e-05,
      "loss": 0.646650743484497,
      "step": 260
    },
    {
      "epoch": 0.488245931283906,
      "grad_norm": 5.447944641113281,
      "learning_rate": 1.5135623869801085e-05,
      "loss": 0.6827661514282226,
      "step": 270
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 2.8371376991271973,
      "learning_rate": 1.495479204339964e-05,
      "loss": 0.6618247509002686,
      "step": 280
    },
    {
      "epoch": 0.5244122965641953,
      "grad_norm": 5.7610273361206055,
      "learning_rate": 1.4773960216998193e-05,
      "loss": 0.730298662185669,
      "step": 290
    },
    {
      "epoch": 0.5424954792043399,
      "grad_norm": 3.4035112857818604,
      "learning_rate": 1.4593128390596747e-05,
      "loss": 0.6781655311584472,
      "step": 300
    },
    {
      "epoch": 0.5605786618444847,
      "grad_norm": 2.777360677719116,
      "learning_rate": 1.44122965641953e-05,
      "loss": 0.6622468948364257,
      "step": 310
    },
    {
      "epoch": 0.5786618444846293,
      "grad_norm": 2.8853609561920166,
      "learning_rate": 1.4231464737793851e-05,
      "loss": 0.6974113464355469,
      "step": 320
    },
    {
      "epoch": 0.596745027124774,
      "grad_norm": 5.351035118103027,
      "learning_rate": 1.4050632911392406e-05,
      "loss": 0.669132137298584,
      "step": 330
    },
    {
      "epoch": 0.6148282097649186,
      "grad_norm": 5.729823589324951,
      "learning_rate": 1.3869801084990959e-05,
      "loss": 0.6258926391601562,
      "step": 340
    },
    {
      "epoch": 0.6329113924050633,
      "grad_norm": 2.727193593978882,
      "learning_rate": 1.3688969258589514e-05,
      "loss": 0.5977882862091064,
      "step": 350
    },
    {
      "epoch": 0.650994575045208,
      "grad_norm": 3.38615345954895,
      "learning_rate": 1.3508137432188066e-05,
      "loss": 0.6304559707641602,
      "step": 360
    },
    {
      "epoch": 0.6690777576853526,
      "grad_norm": 3.4654924869537354,
      "learning_rate": 1.332730560578662e-05,
      "loss": 0.7009489059448242,
      "step": 370
    },
    {
      "epoch": 0.6871609403254972,
      "grad_norm": 2.952023983001709,
      "learning_rate": 1.3146473779385174e-05,
      "loss": 0.7248681068420411,
      "step": 380
    },
    {
      "epoch": 0.705244122965642,
      "grad_norm": 6.402263164520264,
      "learning_rate": 1.2965641952983725e-05,
      "loss": 0.6615688323974609,
      "step": 390
    },
    {
      "epoch": 0.7233273056057866,
      "grad_norm": 3.512462854385376,
      "learning_rate": 1.2784810126582278e-05,
      "loss": 0.6713387966156006,
      "step": 400
    },
    {
      "epoch": 0.7414104882459313,
      "grad_norm": 5.277689456939697,
      "learning_rate": 1.2603978300180833e-05,
      "loss": 0.6121244907379151,
      "step": 410
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 5.59175968170166,
      "learning_rate": 1.2423146473779386e-05,
      "loss": 0.6392055511474609,
      "step": 420
    },
    {
      "epoch": 0.7775768535262206,
      "grad_norm": 2.504314661026001,
      "learning_rate": 1.224231464737794e-05,
      "loss": 0.5826800346374512,
      "step": 430
    },
    {
      "epoch": 0.7956600361663653,
      "grad_norm": 4.175527572631836,
      "learning_rate": 1.2061482820976493e-05,
      "loss": 0.7091936111450196,
      "step": 440
    },
    {
      "epoch": 0.8137432188065099,
      "grad_norm": 3.491664171218872,
      "learning_rate": 1.1880650994575048e-05,
      "loss": 0.6349629878997802,
      "step": 450
    },
    {
      "epoch": 0.8318264014466547,
      "grad_norm": 2.798557996749878,
      "learning_rate": 1.1699819168173599e-05,
      "loss": 0.6395931720733643,
      "step": 460
    },
    {
      "epoch": 0.8499095840867993,
      "grad_norm": 2.9762542247772217,
      "learning_rate": 1.1518987341772152e-05,
      "loss": 0.6638393402099609,
      "step": 470
    },
    {
      "epoch": 0.8679927667269439,
      "grad_norm": 6.243873119354248,
      "learning_rate": 1.1338155515370706e-05,
      "loss": 0.644569206237793,
      "step": 480
    },
    {
      "epoch": 0.8860759493670886,
      "grad_norm": 2.249807596206665,
      "learning_rate": 1.115732368896926e-05,
      "loss": 0.6678397178649902,
      "step": 490
    },
    {
      "epoch": 0.9041591320072333,
      "grad_norm": 2.9070706367492676,
      "learning_rate": 1.0976491862567812e-05,
      "loss": 0.6178314685821533,
      "step": 500
    },
    {
      "epoch": 0.9222423146473779,
      "grad_norm": 2.718322277069092,
      "learning_rate": 1.0795660036166367e-05,
      "loss": 0.7390040397644043,
      "step": 510
    },
    {
      "epoch": 0.9403254972875226,
      "grad_norm": 3.0838351249694824,
      "learning_rate": 1.061482820976492e-05,
      "loss": 0.6753194808959961,
      "step": 520
    },
    {
      "epoch": 0.9584086799276673,
      "grad_norm": 3.509866237640381,
      "learning_rate": 1.0433996383363474e-05,
      "loss": 0.64618821144104,
      "step": 530
    },
    {
      "epoch": 0.976491862567812,
      "grad_norm": 5.329741954803467,
      "learning_rate": 1.0253164556962025e-05,
      "loss": 0.6454991340637207,
      "step": 540
    },
    {
      "epoch": 0.9945750452079566,
      "grad_norm": 3.9165074825286865,
      "learning_rate": 1.0072332730560578e-05,
      "loss": 0.6682183265686035,
      "step": 550
    }
  ],
  "logging_steps": 10,
  "max_steps": 1106,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 701944089600.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
